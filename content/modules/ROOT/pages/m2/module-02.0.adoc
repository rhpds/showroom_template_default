:imagesdir: ../../assets/images
include::../style.adoc[]

== Module 2: Secure microservices access control with {rhossm}

== Business context

* As {corp} expands its digital services, the move to a microservices-based architecture brings greater agility—but also increased complexity in managing how services communicate, scale, and stay secure. Without a consistent approach, deploying updates or ensuring service reliability becomes risky and resource-intensive.

* {rhossm} provides {corp} with a unified solution to manage, observe, and secure its microservices environment. It enables consistent traffic control, real-time visibility, and zero-trust security policies—all without requiring changes to the application code. With capabilities like canary deployments, {corp} can introduce new features more safely and confidently, accelerating delivery while minimizing disruption.

== Technical considerations

To successfully implement {rhossm}, there are a few key technical factors to consider:

* *Namespace and Workload Configuration*: Ensure workloads are deployed in namespaces configured for mesh participation, with sidecar injection enabled (either automatic or manual).

* *mTLS and Identity*: {rhossm} uses mutual TLS (mTLS) to authenticate and encrypt service-to-service traffic. Proper certificate management and identity policies are essential.

* *Authorization Policies*: Fine-grained access control can be implemented using AuthorizationPolicy CRDs to enforce least-privilege communication between services.

* *Traffic Management*: Canary deployments, traffic splitting, and fault injection require well-defined routing rules using VirtualServices and DestinationRules.

* *Observability Stack*: Tools like Kiali, Distributed Tracing, and Prometheus are included for service visualization, tracing, and metrics—ensure they are properly deployed and accessible.

These technical foundations will ensure {corp} can fully realize the benefits of {rhossm} in a production-ready environment.

=== Solution: Red Hat OpenShift Service Mesh

image:m2/mesh-diagram-01.png[]

Red Hat OpenShift Service Mesh adds a transparent layer on existing distributed applications without requiring any changes to the application code. The mesh introduces an easy way to create a network of deployed services that provides discovery, load balancing, service-to-service authentication, failure recovery, metrics, and monitoring. A service mesh also provides more complex operational functionality, including A/B testing, canary releases, access control, and end-to-end authentication.

Microservice architectures split the work of enterprise applications into modular services (deployed as pods in Kuberntetes), which can make scaling and maintenance easier. However, as an enterprise application built on a microservice architecture grows in size and complexity, it can potentially become difficult to understand and manage. Service Mesh can address those architecture problems by capturing or intercepting traffic between services and can modify, redirect, or create new requests to other services in a way that is independant from business logic.

.[.underline]#*Click to learn more about Service Mesh Use Cases*#
[%collapsible]
====

==== Common Use Cases for Service Mesh

A service mesh helps solve several common challenges in modern, cloud-native applications. Here are a few key things you can do with this architecture:

* *Smart Traffic Control*:  
Manage how traffic moves between your services. This helps keep things running smoothly, even when there are problems on the network.

* *Built-in Security*:  
Each service gets its own identity, so you can be sure who’s talking to who. You can also encrypt traffic between services—even if they’re running in different environments.

* *Easy Policy Management*:  
Set rules for how services interact—like who’s allowed to talk to what, and how much traffic they can handle. You make these changes in the mesh, not in your app code.

* *Better Visibility*:  
See how your services depend on each other and track the traffic between them. This makes it easier to spot problems when something goes wrong.


==== Common Challenges addressed

In today’s world of containers and Kubernetes, developers want to focus on writing the actual business logic of their services. But to meet company requirements—like security, monitoring, and reliable networking—they often have to deal with a lot of extra tasks.

Things like setting up secure connections, managing traffic between services, and tracking service behavior are important, but they aren’t part of the busness logic of the service itself.

As a result, each microservice ends up handling more than just its main job. It also has to include things like authentication, error handling, and monitoring—making the system more complex and slowing down development.

image:m2/overhead-01.png[]

Now imagine having to custom-build and manage this operational overhead for every single microservice in an application, especially when these services are written in various programming languages and frameworks. The lack of standardization across the stack results in:

- *Inconsistent Security Policies*: Different teams may implement varying levels of security depending on their tools and knowledge, leading to vulnerabilities.

- *Limited Observability*: Without a unified approach to logging, metrics, and tracing, troubleshooting and performance optimization become tedious and time-consuming.

- *Inefficient Traffic Management*: Developers may struggle to implement traffic control mechanisms like retries, load balancing, or circuit breaking without a standardized solution.

- *Decreased Developer Productivity*: Engineers spend more time on operational concerns than on delivering business value, reducing overall velocity.

- *Loss of Agility in Microservices*: The promised agility of microservices gets undermined by the fragmented, ad-hoc implementation of cross-cutting concerns.

==== How OpenShift Service Mesh Solves These Challenges
image:m2/ossm-use-cases.png[]

OpenShift Service Mesh addresses these challenges by providing a platform-native, unified solution that abstracts away the operational complexities of microservices architectures. It allows developers to focus solely on the business logic of their services while enabling platform teams to:

- *Enforce Consistent Security Policies*: Mutual TLS (mTLS) encryption and fine-grained access controls are implemented out of the box, ensuring all services adhere to a uniform security baseline.

- *Enable Seamless Observability*: Built-in platform tools like Distributed Tracing, Kiali, and Prometheus provide centralized tracing, visualization, and monitoring, giving teams actionable insights across the service mesh.

- *Streamline Traffic Management*: Intelligent traffic routing, load balancing, and support for advanced deployment strategies (e.g., canary releases) simplify managing and optimizing service-to-service communication.

- *Enhance Reliability and Resilience*: Features like automatic retries, circuit breakers, and failover mechanisms ensure high availability even under challenging network conditions.

- *Support Kubernetes-Native Standards*: OpenShift Service Mesh 3’s support for the Kubernetes Gateway API allows for modern, scalable management of ingress and egress traffic across clusters.

With few or no service code changes.

OpenShift Service Mesh uses a proxy container (Envoy) that is injected into a pod to intercept and manage all network traffic for your applications. This proxy allows you to enable powerful features, like traffic control, security, and monitoring, based on the settings you define in the Service Mesh control plane in a way that is decoupled from the application code.

image:m2/ossm-01.png[width=200]

The control plane takes your desired configuration, and its view of the services, and dynamically manages the proxy mesh, updating them as the rules or the environment changes.

image:m2/ossm-02.png[]

The data plane is the communication between services within the mesh itself.
====

== What is Kiali?

Kiali is an observability console for Istio that helps you monitor the structure and health of your service mesh. It displays traffic flow, service relationships, and errors. Kiali also provides metrics, integrates with Grafana, and offers configuration validation.

image:m2/kiali-intro.png[]

You can use the Kiali Operator (provided by Red Hat) to install and run Kiali within your OpenShift cluster.

https://kiali.io/[More information about Kiali]  
  
https://docs.redhat.com/en/documentation/red_hat_openshift_service_mesh/3.0/html/observability/kiali-operator-provided-by-red-hat[Kiali Operator provided by Red Hat]
  
=== Environment Setup

As part of this workshop, certain components (such as {rhossm} and Kiali operators) have been preconfigured in advance to ensure the module can be completed within a short timeframe.


=== Activities Overview:

In this module, you'll get hands-on experience with OpenShift Service Mesh. We’ll walk through the following key activities together:

* *Get to Know the Service Mesh Components*  

** Learn how OpenShift Service Mesh works by exploring its main parts. You’ll see how it gives you visibility and control over how services talk to each other.

* *Secure Service Access with Zero Trust*  

** Use zero trust security principles to make sure only the right services can access sensitive backends—helping protect your applications from unwanted access.

* *Manage Traffic for Safer Deployments*  

** Control how traffic flows between service versions so you can gradually roll out changes, reduce deployment risks, and test updates safely in production.

== Next Steps

Next, we’ll take a closer look at the core parts of {rhossm}—including the control plane, sidecar proxies, and tools for observability. Then we’ll set up namespaces and bring workloads into the mesh using automatic sidecar injection.